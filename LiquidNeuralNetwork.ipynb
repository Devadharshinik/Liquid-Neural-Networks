{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af27dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_dataset(dataset_dir, image_size=(64, 64)):\n",
    "    processed_images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(dataset_dir))\n",
    "    class_map = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_folder = os.path.join(dataset_dir, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            class_images = []\n",
    "            for filename in os.listdir(class_folder):\n",
    "                if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    image_path = os.path.join(class_folder, filename)\n",
    "                    image = cv2.imread(image_path)\n",
    "                    if image is not None:\n",
    "                        image = cv2.resize(image, image_size)\n",
    "                        class_images.append(image)\n",
    "                        labels.append(class_map[class_name])\n",
    "            if class_images:\n",
    "                processed_images.extend(class_images)\n",
    "        else:\n",
    "            print(f\"Warning: '{class_folder}' is not a valid directory.\")\n",
    "    \n",
    "    if not processed_images:\n",
    "        raise ValueError(\"No valid images found in the dataset.\")\n",
    "    \n",
    "    processed_images = np.array(processed_images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return processed_images, labels, class_map\n",
    "\n",
    "    return processed_images, labels, class_map\n",
    "\n",
    "# Define the path to your dataset directory\n",
    "dataset_directory = r\"C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archive (1)\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\"\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "images, labels, class_map = load_dataset(dataset_directory)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d03f64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_lnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')  # Output layer for classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Get input shape and number of classes from the dataset\n",
    "input_shape = train_images[0].shape\n",
    "num_classes = len(class_map)\n",
    "\n",
    "# Build the LNN model\n",
    "model = build_lnn_model(input_shape, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c75740ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for making predictions\n",
    "def preprocess_image(image_path, image_size=(64, 64)):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is not None:\n",
    "        image = cv2.resize(image, image_size)\n",
    "        image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# # Example of how to use the trained model for prediction\n",
    "# new_image_path = r\"C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archive (1)\\Skin cancer ISIC The International Skin Imaging Collaboration\\Test\\seborrheic keratosis\\ISIC_0010809.jpg\"\n",
    "# new_image = preprocess_image(new_image_path)\n",
    "# predictions = model.predict(new_image)\n",
    "# predicted_class = np.argmax(predictions)\n",
    "# predicted_class_name = [k for k, v in class_map.items() if v == predicted_class][0]\n",
    "\n",
    "# print('Predicted class:', predicted_class_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0d5e226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=1./255  # Normalize pixel values\n",
    ")\n",
    "\n",
    "# Example of using data augmentation during training\n",
    "train_datagen = datagen.flow(train_images, train_labels, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eacc3f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "56/56 [==============================] - 55s 656ms/step - loss: 1.9160 - accuracy: 0.3579 - val_loss: 25.9224 - val_accuracy: 0.1540\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 31s 553ms/step - loss: 1.5143 - accuracy: 0.4668 - val_loss: 21.1915 - val_accuracy: 0.1786\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 31s 549ms/step - loss: 1.4222 - accuracy: 0.4980 - val_loss: 20.5163 - val_accuracy: 0.1875\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 29s 510ms/step - loss: 1.3434 - accuracy: 0.5260 - val_loss: 20.9349 - val_accuracy: 0.1496\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 18s 319ms/step - loss: 1.2813 - accuracy: 0.5416 - val_loss: 30.2309 - val_accuracy: 0.1674\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 19s 335ms/step - loss: 1.2841 - accuracy: 0.5394 - val_loss: 27.0851 - val_accuracy: 0.1652\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 16s 286ms/step - loss: 1.2696 - accuracy: 0.5438 - val_loss: 41.9422 - val_accuracy: 0.1585\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 16s 290ms/step - loss: 1.2142 - accuracy: 0.5567 - val_loss: 27.9241 - val_accuracy: 0.1674\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 18s 316ms/step - loss: 1.2109 - accuracy: 0.5701 - val_loss: 38.0164 - val_accuracy: 0.1629\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 18s 316ms/step - loss: 1.1987 - accuracy: 0.5712 - val_loss: 33.9478 - val_accuracy: 0.1607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1428decd0d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "# Load pre-trained DenseNet model (excluding top layers)\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add top layers for classification\n",
    "x = layers.Flatten()(base_model.output)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "output = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the complete model\n",
    "model = models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with data augmentation\n",
    "model.fit(train_datagen, epochs=10, validation_data=(val_images, val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9d222a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute class frequencies\n",
    "class_counts = np.bincount(train_labels)\n",
    "total_samples = np.sum(class_counts)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = total_samples / (len(class_counts) * class_counts)\n",
    "\n",
    "# Convert class weights to dictionary format\n",
    "class_weight_dict = dict(zip(np.unique(train_labels), class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bafa738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 15ms/step\n",
      "14/14 [==============================] - 0s 16ms/step\n",
      "Combined Model Accuracy: 0.20758928571428573\n"
     ]
    }
   ],
   "source": [
    "# Train multiple models with different hyperparameters or architectures\n",
    "model1 = build_lnn_model(input_shape, num_classes)\n",
    "model2 = build_lnn_model(input_shape, num_classes)\n",
    "# Train model1 and model2 using different training strategies\n",
    "\n",
    "# Make predictions using each model\n",
    "predictions1 = model1.predict(val_images)\n",
    "predictions2 = model2.predict(val_images)\n",
    "\n",
    "# Combine predictions using voting or averaging\n",
    "combined_predictions = (predictions1 + predictions2) / 2  # Example of averaging\n",
    "\n",
    "# Evaluate the combined predictions\n",
    "combined_accuracy = np.mean(np.argmax(combined_predictions, axis=1) == val_labels)\n",
    "print('Combined Model Accuracy:', combined_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bce2eeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted class': actinic keratosis\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, image_size=(64, 64)):\n",
    "    # Load the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Failed to load image from '{image_path}'.\")\n",
    "        return None\n",
    "    \n",
    "    # Resize the image to the specified size\n",
    "    image = cv2.resize(image, image_size)\n",
    "    \n",
    "    # Normalize pixel values (optional, depends on model input)\n",
    "    image = image / 255.0  # Assuming pixel values range from 0 to 255\n",
    "    \n",
    "    # Add batch dimension to match model input shape\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def predict_image(model, image_path, class_map):\n",
    "    # Preprocess the image\n",
    "    image = preprocess_image(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    # Make predictions using the model\n",
    "    predictions = model.predict(image)\n",
    "    \n",
    "    # Get the predicted class index\n",
    "    predicted_class_index = np.argmax(predictions[0])\n",
    "    \n",
    "    # Get the predicted class name from the class map\n",
    "    predicted_class_name = [k for k, v in class_map.items() if v == predicted_class_index][0]\n",
    "    \n",
    "    return predicted_class_name\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Desktop\\STUDY\\PROJECTS\\Project sem VI\\archive (1)\\Skin cancer ISIC The International Skin Imaging Collaboration\\Train\\actinic keratosis\\ISIC_0025780.jpg\" # Specify the path to your image file\n",
    "predicted_class = predict_image(model, image_path, class_map)\n",
    "\n",
    "if predicted_class is not None:\n",
    "    print(f\"Predicted class': {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf76867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "\n",
    "# Assuming 'model' is your trained skin cancer classification model\n",
    "model.save('lnn_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec037c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
